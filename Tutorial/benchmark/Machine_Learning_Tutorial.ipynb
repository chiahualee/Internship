{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chiahual/emails_enron ['enron1', 'enron2', 'enron3', 'enron4', 'enron5', 'enron6'] 0\n",
      "/home/chiahual/emails_enron/enron1 ['ham', 'spam'] 1\n",
      "/home/chiahual/emails_enron/enron1/ham [] 3672\n",
      "/home/chiahual/emails_enron/enron1/spam [] 1500\n",
      "/home/chiahual/emails_enron/enron2 ['ham', 'spam'] 1\n",
      "/home/chiahual/emails_enron/enron2/ham [] 4361\n",
      "/home/chiahual/emails_enron/enron2/spam [] 1496\n",
      "/home/chiahual/emails_enron/enron3 ['ham', 'spam'] 1\n",
      "/home/chiahual/emails_enron/enron3/ham [] 4012\n",
      "/home/chiahual/emails_enron/enron3/spam [] 1500\n",
      "/home/chiahual/emails_enron/enron4 ['ham', 'spam'] 1\n",
      "/home/chiahual/emails_enron/enron4/ham [] 1500\n",
      "/home/chiahual/emails_enron/enron4/spam [] 4500\n",
      "/home/chiahual/emails_enron/enron5 ['ham', 'spam'] 1\n",
      "/home/chiahual/emails_enron/enron5/ham [] 1500\n",
      "/home/chiahual/emails_enron/enron5/spam [] 3675\n",
      "/home/chiahual/emails_enron/enron6 ['ham', 'spam'] 1\n",
      "/home/chiahual/emails_enron/enron6/ham [] 1500\n",
      "/home/chiahual/emails_enron/enron6/spam [] 4500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "rootdir = \"/home/chiahual/emails_enron\"\n",
    "\n",
    "for directories, subdirs, files in os.walk(rootdir):\n",
    "    print(directories, subdirs, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chiahual/emails_enron/enron1/ham [] 3672\n",
      "/home/chiahual/emails_enron/enron1/spam [] 1500\n",
      "/home/chiahual/emails_enron/enron2/ham [] 4361\n",
      "/home/chiahual/emails_enron/enron2/spam [] 1496\n",
      "/home/chiahual/emails_enron/enron3/ham [] 4012\n",
      "/home/chiahual/emails_enron/enron3/spam [] 1500\n",
      "/home/chiahual/emails_enron/enron4/ham [] 1500\n",
      "/home/chiahual/emails_enron/enron4/spam [] 4500\n",
      "/home/chiahual/emails_enron/enron5/ham [] 1500\n",
      "/home/chiahual/emails_enron/enron5/spam [] 3675\n",
      "/home/chiahual/emails_enron/enron6/ham [] 1500\n",
      "/home/chiahual/emails_enron/enron6/spam [] 4500\n"
     ]
    }
   ],
   "source": [
    "for directories, subdirs, files in os.walk(rootdir):\n",
    "    if (os.path.split(directories)[1]  == 'ham'):\n",
    "        print(directories, subdirs, len(files))\n",
    "    \n",
    "    if (os.path.split(directories)[1]  == 'spam'):\n",
    "        print(directories, subdirs, len(files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "ham_list = []\n",
    "spam_list = []\n",
    "\n",
    "\n",
    "for directories, subdirs, files in os.walk(rootdir):\n",
    "    for filename in files: \n",
    "        with open(os.path.join(directories, filename), encoding=\"latin-1\") as f:\n",
    "            corpus_text = f.read()\n",
    "            for c in string.punctuation:\n",
    "                corpus_text = corpus_text.replace(c, \"\")  # -- (1) remove all punctuations\n",
    "\n",
    "            text = re.sub(r'\\S*\\d\\S*','',corpus_text) # -- (2) replace words with digits to with empty string e.g. v3\n",
    "            text = re.sub(r'[^\\w\\s]','',text)         # -- (3) replace anything that is not a word character or whitespace character with empty string                                                \n",
    "            text = text.lower()\n",
    "            text = text.lower().split()           # -- (4) remove next line characters(\\n)     \n",
    "\n",
    "            li = []\n",
    "            for token in text:\n",
    "                li.append(token)\n",
    "            if (os.path.split(directories)[1]  == 'ham'):\n",
    "                ham_list.append(\" \".join(li))\n",
    "            else:\n",
    "                spam_list.append(\" \".join(li))                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ham_list): 16545 len(spam_list): 17177\n"
     ]
    }
   ],
   "source": [
    "print(\"len(ham_list): \" + str(len(ham_list)),\"len(spam_list): \" + str(len(spam_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_list=ham_list+spam_list\n",
    "email_label=[0]*len(ham_list)+[1]*len(spam_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=50,max_df=0.8,stop_words=\"english\")\n",
    "X=vectorizer.fit_transform(email_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7180"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33722, 7180)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "folds = 10 \n",
    "one_portion = math.floor(len(email_list)/(folds+1))\n",
    "\n",
    "indices = np.random.permutation(np.arange(len(email_list)))\n",
    "training_idx, test_idx = indices[:one_portion*10],indices[one_portion*10:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Validation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.6 accuracy 0.9625774877650897\n",
      "--- 2.2201170921325684 seconds --- for naive bayes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "lowest_cross_val_error_BNB = np.inf\n",
    "best_alpha = None\n",
    "\n",
    "\n",
    "alpha_values=[1, 0.9, 0.8, 0.7, 0.6]\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=9999999)\n",
    "\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    errors_BNB = []\n",
    "    for train_indices, val_indices in kf.split(training_idx):\n",
    "        \n",
    "        #BernoulliNB\n",
    "        clf = BernoulliNB(alpha=alpha)\n",
    "        clf.fit(X[train_indices], np.array(email_label)[train_indices])\n",
    "        predicted_val_labels_BNB = clf.predict(X[val_indices])\n",
    "        error_BNB = np.mean(predicted_val_labels_BNB != np.array(email_label)[val_indices])\n",
    "        errors_BNB.append(error_BNB)\n",
    "        \n",
    "\n",
    "  \n",
    "    cross_val_error_BNB = np.mean(errors_BNB)\n",
    "\n",
    "#     print('alpha:', alpha, 'cross validation error:', cross_val_error_BNB)\n",
    " \n",
    "    if cross_val_error_BNB < lowest_cross_val_error_BNB:\n",
    "        lowest_cross_val_error_BNB = cross_val_error_BNB\n",
    "        best_alpha = alpha\n",
    "\n",
    "print('Best alpha:', best_alpha, 'accuracy', 1-lowest_cross_val_error_BNB)\n",
    "print(\"--- %s seconds --- for naive bayes\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 5 accuracy 0.8870799347471452\n",
      "--- 212.36545133590698 seconds --- for KNN\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "lowest_cross_val_error_KNN = np.inf\n",
    "best_k = None\n",
    "\n",
    "k_values=[5, 20, 60, 80, 100]\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=9999999)\n",
    "\n",
    "\n",
    "for k in k_values:\n",
    "    errors_KNN = []\n",
    "\n",
    "    for train_indices, val_indices in kf.split(training_idx):\n",
    "        \n",
    "        #KNN\n",
    "        neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "        neigh.fit(X[train_indices], np.array(email_label)[train_indices]) \n",
    "        predicted_val_labels_KNN = neigh.predict(X[val_indices])\n",
    "        error_KNN = np.mean(predicted_val_labels_KNN != np.array(email_label)[val_indices])\n",
    "        errors_KNN.append(error_KNN)\n",
    "        \n",
    "     \n",
    "        \n",
    "    cross_val_error_KNN = np.mean(errors_KNN)\n",
    "\n",
    "#     print('k:', k, 'cross validation error:', cross_val_error_KNN)  \n",
    "  \n",
    "    if cross_val_error_KNN < lowest_cross_val_error_KNN:\n",
    "        lowest_cross_val_error_KNN = cross_val_error_KNN\n",
    "        best_k = k\n",
    "    \n",
    "print('Best k:', best_k, 'accuracy', 1-lowest_cross_val_error_KNN)\n",
    "print(\"--- %s seconds --- for KNN\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9824469820554649\n",
      "--- 5.451224088668823 seconds --- for SVM Linear\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=9999999)\n",
    "\n",
    "\n",
    "\n",
    "errors_SVC = []\n",
    "for train_indices, val_indices in kf.split(training_idx):\n",
    "\n",
    "    #SVC\n",
    "    classifier = LinearSVC()\n",
    "    classifier.fit(X[train_indices],np.array(email_label)[train_indices])\n",
    "    predicted_val_labels_SVC = classifier.predict(X[val_indices])\n",
    "    error_SVC = np.mean(predicted_val_labels_SVC != np.array(email_label)[val_indices])\n",
    "    errors_SVC.append(error_SVC)\n",
    "\n",
    "cross_val_error_SVC = np.mean(errors_SVC)\n",
    "# print(\"cross validation error: \", cross_val_error_SVC)\n",
    "print( 'accuracy', 1-cross_val_error_SVC)\n",
    "print(\"--- %s seconds --- for SVM Linear\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy 0.9742838541666666\n"
     ]
    }
   ],
   "source": [
    "clf_best = BernoulliNB(alpha=0.7)\n",
    "clf_best.fit(X[training_idx], np.array(email_label)[training_idx])\n",
    "predicted_test_labels_BNB = clf_best.predict(X[test_idx])\n",
    "error = np.mean(predicted_test_labels_BNB != np.array(email_label)[test_idx])\n",
    "print(\"Testing Accuracy for Naive Bayes\", 1-error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy for KNN  0.7477213541666667\n"
     ]
    }
   ],
   "source": [
    "neigh_best = KNeighborsClassifier(n_neighbors=k)\n",
    "neigh_best.fit(X[training_idx], np.array(email_label)[training_idx])\n",
    "predicted_test_labels_KNN = neigh_best.predict(X[test_idx])\n",
    "error = np.mean(predicted_test_labels_KNN != np.array(email_label)[test_idx])\n",
    "print(\"Testing Accuracy for KNN \", 1-error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy for SVM Linear 0.9853515625\n"
     ]
    }
   ],
   "source": [
    "SVM_best = LinearSVC()\n",
    "SVM_best.fit(X[training_idx], np.array(email_label)[training_idx])\n",
    "predicted_test_labels_SVM = SVM_best.predict(X[test_idx])\n",
    "error = np.mean(predicted_test_labels_SVM != np.array(email_label)[test_idx])\n",
    "print(\"Testing Accuracy for SVM Linear\", 1-error)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
