{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Tutorial - Document Classification on Enron Email Dataset\n",
    "\n",
    "This tutorial aims to demonstrate the steps to build machine learning models with scikit learn and use the computational resources on Bridges.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial Duration: 1hr\n",
    "\n",
    "Environment: module load AI/anaconda3-5.1.0_gpu\n",
    "\n",
    "You can download the data here: http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/index.html\n",
    "\n",
    "Data Preprocessing: In total, we have 16,545 hams and 17,177 spams. These labeled Enron emails are given in six directories. And under each directories are subfolders holding spam and ham emails in their original form. With this, we can creat lables for our emails (1 for spam and 0 for ham). We first did some data cleansing and extracted the tokenized words as features to build our TF-IDF matrix. Then we randomly sampled our data and split it to train and test.\n",
    "\n",
    "Experimental setup: We trained three classifiers (Naive Bayes, KNN and SVM) with the implementation of scikit-learn. To ensure stability of our model, we utilized 10 fold cross-validation to gauge the effectiveness of our modelâ€™s performance. Lastly, we used the reserved test data to provide an unbiased evaluation of a final model fit on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Explanation on Models:\n",
    "    \n",
    "* Naive Bayes:\n",
    "\n",
    "Naive Bayes classifier is based on the Bayes' Rule and strong (or naive) independence assumptions between features. \n",
    "\n",
    "Read More: https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/\n",
    "\n",
    "\n",
    "* KNN:\n",
    "\n",
    "KNN is also another classic classification algorithm. It stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions).\n",
    "\n",
    "Read More: https://medium.com/@adi.bronshtein/a-quick-introduction-to-k-nearest-neighbors-algorithm-62214cea29c7\n",
    "\n",
    "\n",
    "* Linear SVM\n",
    "\n",
    "SVM performs classification by finding the line that maximizes the margin between the two classes. \n",
    "\n",
    "Read More: https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chiahual/emails_enron ['enron1', 'enron2', 'enron3', 'enron4', 'enron5', 'enron6'] 0\n",
      "/home/chiahual/emails_enron/enron1 ['ham', 'spam'] 1\n",
      "/home/chiahual/emails_enron/enron1/ham [] 3672\n",
      "/home/chiahual/emails_enron/enron1/spam [] 1500\n",
      "/home/chiahual/emails_enron/enron2 ['ham', 'spam'] 1\n",
      "/home/chiahual/emails_enron/enron2/ham [] 4361\n",
      "/home/chiahual/emails_enron/enron2/spam [] 1496\n",
      "/home/chiahual/emails_enron/enron3 ['ham', 'spam'] 1\n",
      "/home/chiahual/emails_enron/enron3/ham [] 4012\n",
      "/home/chiahual/emails_enron/enron3/spam [] 1500\n",
      "/home/chiahual/emails_enron/enron4 ['ham', 'spam'] 1\n",
      "/home/chiahual/emails_enron/enron4/ham [] 1500\n",
      "/home/chiahual/emails_enron/enron4/spam [] 4500\n",
      "/home/chiahual/emails_enron/enron5 ['ham', 'spam'] 1\n",
      "/home/chiahual/emails_enron/enron5/ham [] 1500\n",
      "/home/chiahual/emails_enron/enron5/spam [] 3675\n",
      "/home/chiahual/emails_enron/enron6 ['ham', 'spam'] 1\n",
      "/home/chiahual/emails_enron/enron6/ham [] 1500\n",
      "/home/chiahual/emails_enron/enron6/spam [] 4500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "rootdir = \"/home/chiahual/emails_enron\"\n",
    "\n",
    "for directories, subdirs, files in os.walk(rootdir):\n",
    "    print(directories, subdirs, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chiahual/emails_enron/enron1/ham [] 3672\n",
      "/home/chiahual/emails_enron/enron1/spam [] 1500\n",
      "/home/chiahual/emails_enron/enron2/ham [] 4361\n",
      "/home/chiahual/emails_enron/enron2/spam [] 1496\n",
      "/home/chiahual/emails_enron/enron3/ham [] 4012\n",
      "/home/chiahual/emails_enron/enron3/spam [] 1500\n",
      "/home/chiahual/emails_enron/enron4/ham [] 1500\n",
      "/home/chiahual/emails_enron/enron4/spam [] 4500\n",
      "/home/chiahual/emails_enron/enron5/ham [] 1500\n",
      "/home/chiahual/emails_enron/enron5/spam [] 3675\n",
      "/home/chiahual/emails_enron/enron6/ham [] 1500\n",
      "/home/chiahual/emails_enron/enron6/spam [] 4500\n"
     ]
    }
   ],
   "source": [
    "for directories, subdirs, files in os.walk(rootdir):\n",
    "    if (os.path.split(directories)[1]  == 'ham'):\n",
    "        print(directories, subdirs, len(files))\n",
    "    \n",
    "    if (os.path.split(directories)[1]  == 'spam'):\n",
    "        print(directories, subdirs, len(files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "ham_list = []\n",
    "spam_list = []\n",
    "\n",
    "\n",
    "for directories, subdirs, files in os.walk(rootdir):\n",
    "    for filename in files: \n",
    "        with open(os.path.join(directories, filename), encoding=\"latin-1\") as f:\n",
    "            corpus_text = f.read()\n",
    "            for c in string.punctuation:\n",
    "                corpus_text = corpus_text.replace(c, \"\")  # -- (1) remove all punctuations\n",
    "\n",
    "            text = re.sub(r'\\S*\\d\\S*','',corpus_text) # -- (2) replace words with digits to with empty string e.g. v3\n",
    "            text = re.sub(r'[^\\w\\s]','',text)         # -- (3) replace anything that is not a word character or whitespace character with empty string                                                \n",
    "            text = text.lower()\n",
    "            text = text.lower().split()           # -- (4) remove next line characters(\\n)     \n",
    "\n",
    "            li = []\n",
    "            for token in text:\n",
    "                li.append(token)\n",
    "            if (os.path.split(directories)[1]  == 'ham'):\n",
    "                ham_list.append(\" \".join(li))\n",
    "            else:\n",
    "                spam_list.append(\" \".join(li))                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ham_list): 16545 len(spam_list): 17177\n"
     ]
    }
   ],
   "source": [
    "print(\"len(ham_list): \" + str(len(ham_list)),\"len(spam_list): \" + str(len(spam_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_list=ham_list+spam_list\n",
    "email_label=[0]*len(ham_list)+[1]*len(spam_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=50,max_df=0.8,stop_words=\"english\")\n",
    "X=vectorizer.fit_transform(email_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7180"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33722, 7180)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "folds = 10 \n",
    "one_portion = math.floor(len(email_list)/(folds+1))\n",
    "\n",
    "indices = np.random.permutation(np.arange(len(email_list)))\n",
    "training_idx, test_idx = indices[:one_portion*10],indices[one_portion*10:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Validation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.6 accuracy 0.9625774877650897\n",
      "--- 2.2201170921325684 seconds --- for naive bayes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "lowest_cross_val_error_BNB = np.inf\n",
    "best_alpha = None\n",
    "\n",
    "\n",
    "alpha_values=[1, 0.9, 0.8, 0.7, 0.6]\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=9999999)\n",
    "\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    errors_BNB = []\n",
    "    for train_indices, val_indices in kf.split(training_idx):\n",
    "        \n",
    "        #BernoulliNB\n",
    "        clf = BernoulliNB(alpha=alpha)\n",
    "        clf.fit(X[train_indices], np.array(email_label)[train_indices])\n",
    "        predicted_val_labels_BNB = clf.predict(X[val_indices])\n",
    "        error_BNB = np.mean(predicted_val_labels_BNB != np.array(email_label)[val_indices])\n",
    "        errors_BNB.append(error_BNB)\n",
    "        \n",
    "\n",
    "  \n",
    "    cross_val_error_BNB = np.mean(errors_BNB)\n",
    "\n",
    "#     print('alpha:', alpha, 'cross validation error:', cross_val_error_BNB)\n",
    " \n",
    "    if cross_val_error_BNB < lowest_cross_val_error_BNB:\n",
    "        lowest_cross_val_error_BNB = cross_val_error_BNB\n",
    "        best_alpha = alpha\n",
    "\n",
    "print('Best alpha:', best_alpha, 'accuracy', 1-lowest_cross_val_error_BNB)\n",
    "print(\"--- %s seconds --- for naive bayes\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 5 accuracy 0.8870799347471452\n",
      "--- 212.36545133590698 seconds --- for KNN\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "lowest_cross_val_error_KNN = np.inf\n",
    "best_k = None\n",
    "\n",
    "k_values=[5, 20, 60, 80, 100]\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=9999999)\n",
    "\n",
    "\n",
    "for k in k_values:\n",
    "    errors_KNN = []\n",
    "\n",
    "    for train_indices, val_indices in kf.split(training_idx):\n",
    "        \n",
    "        #KNN\n",
    "        neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "        neigh.fit(X[train_indices], np.array(email_label)[train_indices]) \n",
    "        predicted_val_labels_KNN = neigh.predict(X[val_indices])\n",
    "        error_KNN = np.mean(predicted_val_labels_KNN != np.array(email_label)[val_indices])\n",
    "        errors_KNN.append(error_KNN)\n",
    "        \n",
    "     \n",
    "        \n",
    "    cross_val_error_KNN = np.mean(errors_KNN)\n",
    "\n",
    "#     print('k:', k, 'cross validation error:', cross_val_error_KNN)  \n",
    "  \n",
    "    if cross_val_error_KNN < lowest_cross_val_error_KNN:\n",
    "        lowest_cross_val_error_KNN = cross_val_error_KNN\n",
    "        best_k = k\n",
    "    \n",
    "print('Best k:', best_k, 'accuracy', 1-lowest_cross_val_error_KNN)\n",
    "print(\"--- %s seconds --- for KNN\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9824469820554649\n",
      "--- 5.451224088668823 seconds --- for SVM Linear\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=9999999)\n",
    "\n",
    "\n",
    "\n",
    "errors_SVC = []\n",
    "for train_indices, val_indices in kf.split(training_idx):\n",
    "\n",
    "    #SVC\n",
    "    classifier = LinearSVC()\n",
    "    classifier.fit(X[train_indices],np.array(email_label)[train_indices])\n",
    "    predicted_val_labels_SVC = classifier.predict(X[val_indices])\n",
    "    error_SVC = np.mean(predicted_val_labels_SVC != np.array(email_label)[val_indices])\n",
    "    errors_SVC.append(error_SVC)\n",
    "\n",
    "cross_val_error_SVC = np.mean(errors_SVC)\n",
    "# print(\"cross validation error: \", cross_val_error_SVC)\n",
    "print( 'accuracy', 1-cross_val_error_SVC)\n",
    "print(\"--- %s seconds --- for SVM Linear\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy 0.9742838541666666\n"
     ]
    }
   ],
   "source": [
    "clf_best = BernoulliNB(alpha=0.7)\n",
    "clf_best.fit(X[training_idx], np.array(email_label)[training_idx])\n",
    "predicted_test_labels_BNB = clf_best.predict(X[test_idx])\n",
    "error = np.mean(predicted_test_labels_BNB != np.array(email_label)[test_idx])\n",
    "print(\"Testing Accuracy for Naive Bayes\", 1-error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy for KNN  0.7477213541666667\n"
     ]
    }
   ],
   "source": [
    "neigh_best = KNeighborsClassifier(n_neighbors=k)\n",
    "neigh_best.fit(X[training_idx], np.array(email_label)[training_idx])\n",
    "predicted_test_labels_KNN = neigh_best.predict(X[test_idx])\n",
    "error = np.mean(predicted_test_labels_KNN != np.array(email_label)[test_idx])\n",
    "print(\"Testing Accuracy for KNN \", 1-error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy for SVM Linear 0.9853515625\n"
     ]
    }
   ],
   "source": [
    "SVM_best = LinearSVC()\n",
    "SVM_best.fit(X[training_idx], np.array(email_label)[training_idx])\n",
    "predicted_test_labels_SVM = SVM_best.predict(X[test_idx])\n",
    "error = np.mean(predicted_test_labels_SVM != np.array(email_label)[test_idx])\n",
    "print(\"Testing Accuracy for SVM Linear\", 1-error)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
