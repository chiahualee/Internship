{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data from ssact\n",
    "### Sample sacct command for GPU nodes:\n",
    "sacct -a -P -X -S 071918-00:00:00 -E 072018-23:59:59 --format=Account,AllocTRES,JobName,JobID,User,Partition,Start,State,Submit,ReqMem,Timelimit,NodeList,End -s CANCELLED,TIMEOUT,FAILED,COMPLETED,NODE_FAIL,OUT_OF_MEMORY -r GPU,GPU-shared,GPU-small> today_gpu.csv\n",
    "\n",
    "### Sample sacct command for RM nodes:\n",
    "sacct -a -P -X -S 071918-00:00:00 -E 072018-23:59:59 --format=Account,AllocTRES,JobName,JobID,User,Partition,Start,State,Submit,ReqMem,Timelimit,NodeList,End -s CANCELLED,TIMEOUT,FAILED,COMPLETED,NODE_FAIL,OUT_OF_MEMORY -r RM,RM-shared,RM-small> today_rm.csv\n",
    "\n",
    "### Sample sacct command for LM nodes:\n",
    "sacct -a -P -X -S 071918-00:00:00 -E 072018-23:59:59 --format=Account,AllocTRES,JobName,JobID,User,Partition,Start,State,Submit,ReqMem,Timelimit,NodeList,End -s CANCELLED,TIMEOUT,FAILED,COMPLETED,NODE_FAIL,OUT_OF_MEMORY -r LM> today_lm.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_process_node_partition(df):\n",
    "    xl = []\n",
    "    l =[]\n",
    "    for a in range(df[\"NodeList\"].shape[0]):\n",
    "        if df[\"NodeList\"][a][0]==\"x\":\n",
    "            xl.append(a)\n",
    "        elif df[\"NodeList\"][a][0]==\"l\":\n",
    "            l.append(a)\n",
    "    #xlm\n",
    "    xlm=df.iloc[xl,:]\n",
    "    xlm[\"NodeList_1\"]=xlm[\"NodeList\"].str.replace(\"xl\",\"\")\n",
    "    xlm.loc[:,\"type\"]=\"xl\"\n",
    "    #lm    \n",
    "    lm=df.iloc[l,:]\n",
    "    lm[\"NodeList_1\"]=lm[\"NodeList\"].str.replace(\"l\",\"\")\n",
    "    lm.loc[:,\"type\"]=\"l\"\n",
    "    all_lm=pd.concat([lm,xlm])\n",
    "    return all_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_AllocTRES(df,fileName):\n",
    "    if \"gpu\" in str(fileName):\n",
    "        df[\"Alloc_NODE\"]=np.where(df['AllocTRES']=='Not Allocated', 0, df['AllocTRES'].str.split(\",\").str[2].str[5:])\n",
    "        df[\"Alloc_gres/gpu\"]=np.where(df['AllocTRES']=='Not Allocated', 0,df['AllocTRES'])\n",
    "        df[\"Alloc_gres/gpu\"]=np.where(df['Alloc_gres/gpu'].str.split(\",\").str[4].str.contains(\":\"),df['Alloc_gres/gpu'].str.split(\",\").str[4].str[9:12],df['Alloc_gres/gpu'].str.split(\",\").str[5].str[9:12])\n",
    "        df[\"Alloc_gres/gpu\"]=np.where(df['Alloc_gres/gpu']=='p10', 'p100',df['Alloc_gres/gpu'])\n",
    "        df[\"Alloc_GPU\"]=np.where(df['AllocTRES']=='Not Allocated',0, df['AllocTRES'])\n",
    "        df[\"Alloc_GPU\"]=np.where(df['Alloc_GPU'].str.split(\",\").str[4].str.contains(\":\"),df['Alloc_GPU'].str.split(\",\").str[4].str[-2:],df['Alloc_GPU'].str.split(\",\").str[5].str[-2:])\n",
    "        df[\"Alloc_GPU\"]=df[\"Alloc_GPU\"].str.replace(\"=\",\"\")\n",
    "    elif \"rm\" in str(df):\n",
    "        df[\"Alloc_CPU\"]=np.where(df['AllocTRES']=='Not Allocated', 0, df['AllocTRES'].str.split(\",\").str[0].str[4:])\n",
    "        df[\"Alloc_MEM\"]=np.where(df['AllocTRES']=='Not Allocated', 0, df['AllocTRES'].str.split(\",\").str[1].str[4:-1])\n",
    "        df[\"Alloc_NODE\"]=np.where(df['AllocTRES']=='Not Allocated', 0, df['AllocTRES'].str.split(\",\").str[2].str[5:])\n",
    "    else:\n",
    "        df[\"Alloc_CPU\"]=np.where(df['AllocTRES']=='Not Allocated', 0, df['AllocTRES'].str.split(\",\").str[0].str[4:])\n",
    "        df[\"Alloc_MEM\"]=np.where(df['AllocTRES']=='Not Allocated', 0, df['AllocTRES'].str.split(\",\").str[1].str[4:-1])\n",
    "        df[\"Alloc_NODE\"]=np.where(df['AllocTRES']=='Not Allocated', 0, df['AllocTRES'].str.split(\",\").str[2].str[5:])\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_NodeList_Row(row):\n",
    "    allNum = []\n",
    "    [[allNum.append(i) for i in range(int(a.split(\"-\")[0]), int(a.split(\"-\")[1])+1, 1)] if \"-\" in a else allNum.append(int(a)) for a in row.split(\",\")] \n",
    "    return allNum\n",
    "\n",
    "def process_NodeList(df,fileName):\n",
    "    all_arr=[]\n",
    "    if \"gpu\" in str(fileName):\n",
    "        df[\"NodeList_1\"]=df[\"NodeList\"].str.replace(\"gpu\",\"\")\n",
    "    elif \"rm\" in str(fileName):\n",
    "        df[\"NodeList_1\"]=df[\"NodeList\"].str.replace(\"r\",\"\")\n",
    "    else:\n",
    "        df=lm_process_node_partition(df)\n",
    "    df[\"NodeList_1\"]=df[\"NodeList_1\"].str.replace(\"[\",\"\")\n",
    "    df[\"NodeList_1\"]=df[\"NodeList_1\"].str.replace(\"]\",\"\")\n",
    "    for row in df[\"NodeList_1\"]:\n",
    "        if row==\"None assigned\":\n",
    "            all_arr.append(None)\n",
    "        elif \"-\" not in row and \",\" not in row:\n",
    "            all_arr.append([int(row)])\n",
    "        else:\n",
    "            all_arr.append(process_NodeList_Row(row))\n",
    "    df[\"nodeArray\"]=all_arr\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the requested time to seconds\n",
    "def process_TimeLimit(df):\n",
    "    df[\"Timelimit\"] = df[\"Timelimit\"].str.replace(\"-\",\":\") \n",
    "    temp=df['Timelimit'].str.split(\":\")\n",
    "    df['ReqTime']=np.where(temp.str.len()==3,temp.str[0].astype(int)*3600+temp.str[1].astype(int)*60+temp.str[2].astype(int),temp.str[0].astype(int)*86400+temp.str[1].astype(int)*3600+temp.str[2].astype(int)*60+temp.str[3].fillna(0).astype(int))\n",
    "    df=df.drop(['Timelimit'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/pandas/core/indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "def sacct_data_cleansing(fileName):\n",
    "\n",
    "    df = pd.read_csv(fileName, sep='|',error_bad_lines=False)\n",
    "    df = df.fillna(\"Not Allocated\")\n",
    "    df = df.sort_values('Start')\n",
    "    df = process_AllocTRES(df,fileName)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"End\"]=np.where(df['End']=='Unknown',None,df['End'])\n",
    "    df[\"Start\"]=np.where(df['Start']=='Unknown',None,df['Start'])\n",
    "    df = process_NodeList(df,fileName)\n",
    "    df=process_TimeLimit(df)\n",
    "    return df.drop(['AllocTRES','NodeList_1'], axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "df_gpu=sacct_data_cleansing(\"today_gpu.csv\")\n",
    "df_gpu.to_csv(\"gpu.csv\")\n",
    "df_rm=sacct_data_cleansing(\"today_rm.csv\")\n",
    "df_rm.to_csv(\"rm.csv\")\n",
    "df_lm=sacct_data_cleansing(\"today_lm.csv\")\n",
    "df_lm.to_csv(\"lm.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data from ssactmgr\n",
    "### Get Events on downed or draining nodes on clusters.\n",
    "### Sample sacctmgr command:\n",
    "sacctmgr show events -P event=node Start=071918-00:00:00 End=072018-23:59:59 > today_state.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sacctmgr_data_cleansing(fileName, df):\n",
    "    df_state=pd.read_csv(\"today_state.csv\", sep='|',error_bad_lines=False)\n",
    "    df_state=df_state.drop([\"Cluster\",\"User\"], axis=1)\n",
    "    \n",
    "    if \"gpu\" in fileName:\n",
    "        df_state= df_state.drop(df_state[df_state[\"NodeName\"].str[:3]!='gpu'].index)\n",
    "        df_state[\"Alloc_gres/gpu\"]=np.where(df_state[\"NodeName\"].str[3:].astype(int)<17,\"k80\",\"p100\")\n",
    "        df_state[\"nodeArray\"]=[[row] for row in df_state[\"NodeName\"].str[3:].astype(int)]\n",
    "        df_state[\"Alloc_GPU\"]=np.where(df_state[\"Alloc_gres/gpu\"]==\"k80\",4,2)\n",
    "\n",
    "\n",
    "    elif \"rm\" in fileName:\n",
    "        df_state= df_state.drop(df_state[df_state[\"NodeName\"].str[0]!='r'].index)\n",
    "        df_state[\"nodeArray\"]=[[row] for row in df_state[\"NodeName\"].str[1:].astype(int)]\n",
    "        df_state[\"Alloc_CPU\"]=28\n",
    "        \n",
    "    else:\n",
    "\n",
    "        df_lm= df_state.drop(df_state[df_state[\"NodeName\"].str[0]!='l'].index)\n",
    "        df_lm[\"nodeArray\"]=[[row] for row in df_lm[\"NodeName\"].str[1:].astype(int)]\n",
    "        df_lm[\"type\"]=\"l\"\n",
    "        df_lm[\"Alloc_MEM\"]=3000\n",
    "        df_xlm= df_state.drop(df_state[df_state[\"NodeName\"].str[:2]!='xl'].index)\n",
    "        df_xlm[\"type\"]=\"xl\"\n",
    "        df_xlm[\"Alloc_MEM\"]=12000\n",
    "        df_xlm[\"nodeArray\"]=[[row] for row in df_xlm[\"NodeName\"].str[2:].astype(int)]\n",
    "        df_state=df_lm.append(df_xlm)\n",
    "   \n",
    "    \n",
    "    df_state[\"State\"]=df_state[\"State\"].str.replace(\"$\",\"\") \n",
    "    df_state[\"State\"]=df_state[\"State\"].str.replace(\"*\",\"\") \n",
    "    df_state.rename(columns = {'TimeStart':'Start','TimeEnd':'End'}, inplace = True)\n",
    "    df_state=df_state.drop([\"NodeName\"], axis=1)\n",
    "    df_state[\"Alloc_NODE\"]=1\n",
    "    df_all=df_state.append(df)\n",
    "    df_all = df_all.reset_index(drop=True)\n",
    "    df_all[\"Alloc_NODE\"]=df_all[\"Alloc_NODE\"].fillna(0)\n",
    "    df_all[\"State\"]=np.where(df_all[\"State\"].str.contains(\"CANCELLED\"),\"CANCELLED\",df_all[\"State\"])\n",
    "    \n",
    "    if \"gpu\" in fileName:\n",
    "        df_all[\"Alloc_GPU\"]=df_all[\"Alloc_GPU\"].fillna(0)\n",
    "        df_all[\"GPU_used\"]=df_all[\"Alloc_GPU\"].astype(float)/df_all[\"Alloc_NODE\"].astype(float)\n",
    "        \n",
    "    elif \"rm\" in fileName:\n",
    "\n",
    "        df_all[\"Alloc_CPU\"]=df_all[\"Alloc_CPU\"].fillna(0)\n",
    "        df_all[\"CPU_used\"]=df_all[\"Alloc_CPU\"].astype(float)/df_all[\"Alloc_NODE\"].astype(float)\n",
    "    else:\n",
    "        df_all[\"Alloc_CPU\"]=df_all[\"Alloc_CPU\"].fillna(0)\n",
    "        df_all[\"Mem_used\"]=df_all[\"Alloc_MEM\"].astype(float)/df_all[\"Alloc_NODE\"].astype(float)\n",
    "        df_all[\"Partition\"]=df_all[\"type\"]\n",
    "        df_all=df_all.drop([\"type\"], axis=1)\n",
    "        \n",
    "\n",
    "    return df_all\n",
    "       \n",
    "df_all_gpu=sacctmgr_data_cleansing(\"today_gpu.csv\",df_gpu)\n",
    "df_all_rm=sacctmgr_data_cleansing(\"today_rm.csv\",df_rm)\n",
    "df_all_lm=sacctmgr_data_cleansing(\"today_lm.csv\",df_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Account',\n",
       " 'Alloc_GPU',\n",
       " 'Alloc_NODE',\n",
       " 'Alloc_gres/gpu',\n",
       " 'End',\n",
       " 'JobID',\n",
       " 'JobName',\n",
       " 'NodeList',\n",
       " 'Partition',\n",
       " 'Reason',\n",
       " 'ReqMem',\n",
       " 'ReqTime',\n",
       " 'Start',\n",
       " 'State',\n",
       " 'Submit',\n",
       " 'User',\n",
       " 'nodeArray',\n",
       " 'GPU_used']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_all_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Account',\n",
       " 'Alloc_CPU',\n",
       " 'Alloc_MEM',\n",
       " 'Alloc_NODE',\n",
       " 'End',\n",
       " 'JobID',\n",
       " 'JobName',\n",
       " 'NodeList',\n",
       " 'Partition',\n",
       " 'Reason',\n",
       " 'ReqMem',\n",
       " 'ReqTime',\n",
       " 'Start',\n",
       " 'State',\n",
       " 'Submit',\n",
       " 'User',\n",
       " 'nodeArray',\n",
       " 'CPU_used']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_all_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Account',\n",
       " 'Alloc_CPU',\n",
       " 'Alloc_MEM',\n",
       " 'Alloc_NODE',\n",
       " 'End',\n",
       " 'JobID',\n",
       " 'JobName',\n",
       " 'NodeList',\n",
       " 'Partition',\n",
       " 'Reason',\n",
       " 'ReqMem',\n",
       " 'ReqTime',\n",
       " 'Start',\n",
       " 'State',\n",
       " 'Submit',\n",
       " 'User',\n",
       " 'nodeArray',\n",
       " 'Mem_used']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_all_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform start and end time to minute per row\n",
    "*** This is how I transformed the data (like taking a snapshot at a specific point of time): If a job has a start time of 2018-07-19T13:28:35 and end time of 2018-07-19T13:32:21 in sacct, this single job will be converted to four rows with timestamp like the following:\n",
    "\n",
    "2018-07-19T13:29:00\n",
    "\n",
    "2018-07-19T13:30:00\n",
    "\n",
    "2018-07-19T13:31:00\n",
    "\n",
    "2018-07-19T13:32:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For GPU/RM/LM Utilization graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "import dateutil.parser\n",
    "\n",
    "def perdelta(start, end, delta, job ):\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        yield curr,job[0],job[1],job[2],job[3],job[4],job[5],job[6],job[7],job[8],job[9],job[10],job[11],job[12],job[13],job[14],job[15],job[16],job[17],job[18]\n",
    "        curr += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_start_end_time(df_util):\n",
    "    temp_util = []\n",
    "    for a in range(df_util.shape[0]):\n",
    "        temp_util_time=[]\n",
    "        startdate=dateutil.parser.parse(df_util.iloc[a,:][\"Start\"])\n",
    "        enddate=dateutil.parser.parse(df_util.iloc[a,:][\"fakeEnd\"])+timedelta(seconds=1)\n",
    "        for result in perdelta(startdate,enddate,timedelta(minutes=1),df_util.iloc[a,:]):\n",
    "            if result[0]==startdate and str(result[0])[17:]!=\"00\":\n",
    "                pass\n",
    "            else:\n",
    "                temp_util_time.append(result)\n",
    "        temp_util.append(pd.DataFrame(temp_util_time))\n",
    "    return temp_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTimeMap(df):\n",
    "    time=list(df[0])\n",
    "    timeMaps = {}\n",
    "    for i in range(len(time)):\n",
    "        if time[i] not in timeMaps:\n",
    "            timeMaps[time[i]]=[i]\n",
    "        else:\n",
    "            timeMaps[time[i]].append(i)\n",
    "    return timeMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNodeUsage(fileName,result):\n",
    "    all_data=[]\n",
    "    if \"gpu\" in fileName:  \n",
    "        for key, value in createTimeMap(result).items():\n",
    "            states = {}\n",
    "            gpus = {}\n",
    "            types = {}\n",
    "            partitions = {}\n",
    "            for i in value:\n",
    "                row=result.iloc[i]\n",
    "                for a in row[17].split(\",\"):\n",
    "                    if a not in gpus:\n",
    "                        states[a] = row[14]\n",
    "                        partitions[a] = row[9]\n",
    "                        types[a] = row[4]\n",
    "                        gpus[a]=row[18]\n",
    "                    else:\n",
    "                        if row[16]==\"COMPLETED\" or row[14]==\"TIMEOUT\" or row[14]==\"CANCELLED\" or row[14]==\"NODE_FAIL\" or row[14]==\"OUT_OF_MEMORY\":\n",
    "                            gpus[a] = (gpus.get(a)+row[18])\n",
    "\n",
    "\n",
    "            minute=pd.concat([pd.DataFrame(list(gpus.items())),pd.DataFrame(list(types.values())),pd.DataFrame(list(states.values())),pd.DataFrame(list(partitions.values())),pd.DataFrame([key]*len(gpus))],axis=1)    \n",
    "            all_data.append(minute)  \n",
    "    else:\n",
    "        for key, value in createTimeMap(result).items():\n",
    "            states = {}\n",
    "            cpu_OR_mem = {}\n",
    "            partitions = {}\n",
    "            for i in value:\n",
    "                row=result.iloc[i]\n",
    "                for a in row[17].split(\",\"):\n",
    "                    if a not in cpu_OR_mem:\n",
    "                        \n",
    "                        states[a] = row[14]\n",
    "                        partitions[a] = row[9]\n",
    "                        cpu_OR_mem[a]=row[18]\n",
    "                    else:\n",
    "                        if row[16]==\"COMPLETED\" or row[14]==\"TIMEOUT\" or row[14]==\"CANCELLED\" or row[14]==\"NODE_FAIL\" or row[14]==\"OUT_OF_MEMORY\":\n",
    "                            cpu_OR_mem[a] =(cpu_OR_mem.get(a)+row[18])\n",
    "\n",
    "\n",
    "            minute=pd.concat([pd.DataFrame(list(cpu_OR_mem.items())),pd.DataFrame(list(states.values())),pd.DataFrame(list(partitions.values())),pd.DataFrame([key]*len(cpu_OR_mem))],axis=1)    \n",
    "            all_data.append(minute)  \n",
    "        \n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "def utilization_graph_data(fileName,df):\n",
    "    df_util=df.dropna(subset=[\"Start\",\"End\"])\n",
    "    df_util=df_util.drop(df_util[df_util.End=='Unknown'].index)\n",
    "    \n",
    "    if \"gpu\" in fileName:\n",
    "        df_util=df_util.dropna(subset=[\"Alloc_gres/gpu\"])\n",
    "   \n",
    "    df_util[\"fakeEnd\"]=df_util[\"End\"].str[:17]+\"59\"\n",
    "    \n",
    "    temp_util=transform_start_end_time(df_util)\n",
    "    result = pd.concat(temp_util)\n",
    "    result = result.reset_index(drop=True)\n",
    "    result[0] = pd.to_datetime(result[0])\n",
    "    result[0]=result[0].map(lambda x: x.replace(second=0))\n",
    "    result[17]=result[17].astype(\"str\")\n",
    "    result[17]=result[17].str.replace(\"[\",\"\")\n",
    "    result[17]=result[17].str.replace(\"]\",\"\")\n",
    "    all_data=createNodeUsage(fileName,result)\n",
    "    all_data_df = pd.concat(all_data)\n",
    "    \n",
    "    if \"gpu\" in fileName:\n",
    "        all_data_df.columns = [\"Node\",\"gpu\",\"type\",\"state\",\"partition\",\"time\"]\n",
    "    elif \"rm\" in fileName:\n",
    "        all_data_df.columns = [\"Node\",\"core\",\"state\",\"partition\",\"time\"]\n",
    "    else:\n",
    "        all_data_df.columns = [\"Node\",\"mem\",\"state\",\"nodeType\",\"time\"]\n",
    "    \n",
    "    all_data_df2=all_data_df.reset_index(drop=True)\n",
    "    all_data_df2['time']= all_data_df2['time'].map(lambda x: dt.datetime.strftime(x, '%Y-%m-%dT%H:%M:%SZ'))\n",
    "    all_data_df2[\"time\"]=all_data_df2[\"time\"].str[:-1]\n",
    "    \n",
    "    if \"gpu\" in fileName:\n",
    "        all_data_df2[\"partition\"]=all_data_df2[\"partition\"].fillna(\"NA\")\n",
    "        temp=all_data_df2.groupby(['time',\"gpu\",\"type\",\"partition\",\"state\"])['Node'].count().reset_index()\n",
    "        temp.to_csv(\"gpu_level.csv\")\n",
    "        \n",
    "    elif \"rm\" in fileName:\n",
    "        all_data_df2[\"partition\"]=all_data_df2[\"partition\"].fillna(\"NA\")\n",
    "        temp=all_data_df2.groupby(['time',\"core\",\"partition\",\"state\"])['Node'].count().reset_index()\n",
    "        temp.to_csv(\"rm_level.csv\")\n",
    "        \n",
    "    else:\n",
    "        all_data_df2[\"nodeType\"]=all_data_df2[\"nodeType\"].fillna(\"NA\")\n",
    "        temp=all_data_df2.groupby(['time',\"mem\",\"nodeType\",\"state\"])['Node'].count().reset_index()\n",
    "        temp.to_csv(\"lm_level.csv\")\n",
    "                \n",
    "    return temp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 45 ms, total: 1min 15s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gpu_util_graph_data=utilization_graph_data(\"today_gpu.csv\",df_all_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpu_util_graph_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-819ef263fd0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgpu_util_graph_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gpu_util_graph_data' is not defined"
     ]
    }
   ],
   "source": [
    "gpu_util_graph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 10s, sys: 1.55 s, total: 10min 12s\n",
      "Wall time: 10min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rm_util_graph_data=utilization_graph_data(\"today_rm.csv\",df_all_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>core</th>\n",
       "      <th>partition</th>\n",
       "      <th>state</th>\n",
       "      <th>Node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-16T15:40:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>RM</td>\n",
       "      <td>TIMEOUT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-16T15:41:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>RM</td>\n",
       "      <td>TIMEOUT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-16T15:42:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>RM</td>\n",
       "      <td>TIMEOUT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-16T15:43:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>RM</td>\n",
       "      <td>TIMEOUT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-16T15:44:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>RM</td>\n",
       "      <td>TIMEOUT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  core partition    state  Node\n",
       "0  2018-07-16T15:40:00  28.0        RM  TIMEOUT     1\n",
       "1  2018-07-16T15:41:00  28.0        RM  TIMEOUT     1\n",
       "2  2018-07-16T15:42:00  28.0        RM  TIMEOUT     1\n",
       "3  2018-07-16T15:43:00  28.0        RM  TIMEOUT     1\n",
       "4  2018-07-16T15:44:00  28.0        RM  TIMEOUT     1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_util_graph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parser must be a string or character stream, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-5fb135943e06>\u001b[0m in \u001b[0;36mutilization_graph_data\u001b[0;34m(fileName, df)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf_util\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fakeEnd\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_util\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"End\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"59\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtemp_util\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_start_end_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_util\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_util\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-0c7d2a0307d0>\u001b[0m in \u001b[0;36mtransform_start_end_time\u001b[0;34m(df_backlog)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_backlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtemp_backlog_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mstartdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdateutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_backlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Submit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0menddate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdateutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_backlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fakeStart\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mperdelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartdate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menddate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_backlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/dateutil/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparserinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/dateutil/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m                                                       second=0, microsecond=0)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipped_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/dateutil/parser.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self, timestr, dayfirst, yearfirst, fuzzy, fuzzy_with_tokens)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_timelex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# Splits the timestr into tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;31m# keep up with the last token skipped so we can recombine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/dateutil/parser.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(cls, s)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/dateutil/parser.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, instream)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'read'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             raise TypeError('Parser must be a string or character stream, not '\n\u001b[0;32m---> 61\u001b[0;31m                             '{itype}'.format(itype=instream.__class__.__name__))\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Parser must be a string or character stream, not float"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lm_util_graph_data=utilization_graph_data(\"today_lm.csv\",df_all_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>mem</th>\n",
       "      <th>nodeType</th>\n",
       "      <th>state</th>\n",
       "      <th>Node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-10T23:30:00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>xl</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-10T23:31:00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>xl</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-10T23:32:00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>xl</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-10T23:33:00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>xl</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-10T23:34:00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>xl</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    mem nodeType      state  Node\n",
       "0  2018-07-10T23:30:00  720.0       xl  COMPLETED     1\n",
       "1  2018-07-10T23:31:00  720.0       xl  COMPLETED     1\n",
       "2  2018-07-10T23:32:00  720.0       xl  COMPLETED     1\n",
       "3  2018-07-10T23:33:00  720.0       xl  COMPLETED     1\n",
       "4  2018-07-10T23:34:00  720.0       xl  COMPLETED     1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_util_graph_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For GPU/RM/LM Backlog graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_start_end_time(df_backlog):\n",
    "    temp_backlog = []\n",
    "    for a in range(df_backlog.shape[0]):\n",
    "        temp_backlog_time=[]\n",
    "        startdate=dateutil.parser.parse(df_backlog.iloc[a,:][\"Submit\"])\n",
    "        enddate=dateutil.parser.parse(df_backlog.iloc[a,:][\"fakeStart\"])+timedelta(seconds=1)\n",
    "        for result in perdelta(startdate,enddate,timedelta(minutes=1),df_backlog.iloc[a,:]):\n",
    "            if result[0]==startdate and str(result[0])[17:]!=\"00\":\n",
    "                pass\n",
    "            else:\n",
    "                temp_backlog_time.append(result)\n",
    "        temp_backlog.append(pd.DataFrame(temp_backlog_time))\n",
    "\n",
    "        \n",
    "    \n",
    "    return temp_backlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backlog_graph_data(fileName,df):    \n",
    "    df_backlog=df.dropna(subset=[\"Start\",\"End\",\"Submit\"])\n",
    "    df_backlog = df_backlog.drop(df_backlog[df_backlog.End=='Unknown'].index)\n",
    "    df_backlog = df_backlog.drop(df_backlog[df_backlog.NodeList=='None assigned'].index)\n",
    "    df_backlog=df_backlog.reset_index(drop=True)\n",
    "    df_backlog[\"fakeStart\"]=df_backlog[\"Start\"].str[:17]+\"59\"\n",
    "    \n",
    "    if \"gpu\" in fileName:\n",
    "        df_backlog=df_backlog.dropna(subset=[\"Alloc_gres/gpu\"])    \n",
    "    \n",
    "    temp_backlog=transform_start_end_time(df_backlog)\n",
    "    \n",
    "    result = pd.concat(temp_backlog)\n",
    "    result = result.reset_index(drop=True)\n",
    "    \n",
    "    if \"gpu\" in fileName:\n",
    "        result_small_user=result.iloc[:,[0,4,6,9,12,16]]\n",
    "        result_small_user.columns=[\"time\",\"nodeType\",\"jobid\",\"partition\",\"reqTime\",\"user\"]\n",
    "\n",
    "    elif \"rm\" in fileName:\n",
    "        result_small_user=result.iloc[:,[0,6,9,12,16]]\n",
    "        result_small_user.columns=[\"time\",\"jobid\",\"partition\",\"reqTime\",\"user\"]\n",
    "        \n",
    "\n",
    "    else:\n",
    "        result_small_user=result.iloc[:,[0,3,6,9,12,16]]\n",
    "        result_small_user.columns=[\"time\",\"mem\",\"jobid\",\"nodeType\",\"reqTime\",\"user\"]\n",
    "        \n",
    "        \n",
    "    result_small_user['time']=result_small_user['time'].map(lambda x: dt.datetime.strftime(x, '%Y-%m-%dT%H:%M:%SZ'))\n",
    "    result_small_user['time']=result_small_user['time'].str[:-1]\n",
    "\n",
    "    \n",
    "    if \"gpu\" in fileName:\n",
    "        temp=result_small_user.groupby([\"time\",\"partition\",\"nodeType\",\"user\"]).agg({'reqTime':'sum','jobid':'count'}).reset_index()\n",
    "        temp.to_csv(\"backlog_gpu.csv\")\n",
    "    elif \"rm\" in fileName:\n",
    "        temp=result_small_user.groupby([\"time\",\"partition\",\"user\"]).agg({'reqTime':'sum','jobid':'count'}).reset_index()\n",
    "        temp.to_csv(\"backlog_rm.csv\")\n",
    "\n",
    "    else:\n",
    "        temp=result_small_user.groupby([\"time\",\"nodeType\",\"user\"]).agg({'mem':'sum','reqTime':'sum','jobid':'count'}).reset_index()\n",
    "        temp.to_csv(\"backlog_lm.csv\") \n",
    "    \n",
    "    \n",
    "    return temp\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 39s, sys: 886 ms, total: 4min 40s\n",
      "Wall time: 4min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gpu_backlog_graph_data=backlog_graph_data(\"today_gpu.csv\",df_all_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>partition</th>\n",
       "      <th>nodeType</th>\n",
       "      <th>user</th>\n",
       "      <th>reqTime</th>\n",
       "      <th>jobid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-09T13:26:45</td>\n",
       "      <td>GPU</td>\n",
       "      <td>p100</td>\n",
       "      <td>jqwang</td>\n",
       "      <td>172800.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-09T13:26:48</td>\n",
       "      <td>GPU</td>\n",
       "      <td>p100</td>\n",
       "      <td>jqwang</td>\n",
       "      <td>172800.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-09T13:26:57</td>\n",
       "      <td>GPU</td>\n",
       "      <td>p100</td>\n",
       "      <td>jqwang</td>\n",
       "      <td>172800.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-09T13:27:45</td>\n",
       "      <td>GPU</td>\n",
       "      <td>p100</td>\n",
       "      <td>jqwang</td>\n",
       "      <td>172800.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-09T13:27:48</td>\n",
       "      <td>GPU</td>\n",
       "      <td>p100</td>\n",
       "      <td>jqwang</td>\n",
       "      <td>172800.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time partition nodeType    user   reqTime  jobid\n",
       "0  2018-07-09T13:26:45       GPU     p100  jqwang  172800.0      1\n",
       "1  2018-07-09T13:26:48       GPU     p100  jqwang  172800.0      1\n",
       "2  2018-07-09T13:26:57       GPU     p100  jqwang  172800.0      1\n",
       "3  2018-07-09T13:27:45       GPU     p100  jqwang  172800.0      1\n",
       "4  2018-07-09T13:27:48       GPU     p100  jqwang  172800.0      1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_backlog_graph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 14s, sys: 576 ms, total: 3min 15s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rm_backlog_graph_data=backlog_graph_data(\"today_rm.csv\",df_all_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>partition</th>\n",
       "      <th>user</th>\n",
       "      <th>reqTime</th>\n",
       "      <th>jobid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-12T10:18:25</td>\n",
       "      <td>RM</td>\n",
       "      <td>ahazel3</td>\n",
       "      <td>172800.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-12T10:19:25</td>\n",
       "      <td>RM</td>\n",
       "      <td>ahazel3</td>\n",
       "      <td>172800.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-12T10:20:25</td>\n",
       "      <td>RM</td>\n",
       "      <td>ahazel3</td>\n",
       "      <td>172800.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-12T10:21:25</td>\n",
       "      <td>RM</td>\n",
       "      <td>ahazel3</td>\n",
       "      <td>172800.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-12T10:22:25</td>\n",
       "      <td>RM</td>\n",
       "      <td>ahazel3</td>\n",
       "      <td>172800.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time partition     user   reqTime  jobid\n",
       "0  2018-07-12T10:18:25        RM  ahazel3  172800.0      1\n",
       "1  2018-07-12T10:19:25        RM  ahazel3  172800.0      1\n",
       "2  2018-07-12T10:20:25        RM  ahazel3  172800.0      1\n",
       "3  2018-07-12T10:21:25        RM  ahazel3  172800.0      1\n",
       "4  2018-07-12T10:22:25        RM  ahazel3  172800.0      1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_backlog_graph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/packages/AI/anaconda3-5.1.0_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.4 s, sys: 170 ms, total: 47.6 s\n",
      "Wall time: 47.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lm_backlog_graph_data=backlog_graph_data(\"today_lm.csv\",df_all_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>nodeType</th>\n",
       "      <th>user</th>\n",
       "      <th>mem</th>\n",
       "      <th>reqTime</th>\n",
       "      <th>jobid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-10T23:28:38</td>\n",
       "      <td>l</td>\n",
       "      <td>macmanes</td>\n",
       "      <td>720</td>\n",
       "      <td>1209600.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-10T23:28:38</td>\n",
       "      <td>xl</td>\n",
       "      <td>macmanes</td>\n",
       "      <td>720</td>\n",
       "      <td>1209600.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-10T23:29:38</td>\n",
       "      <td>l</td>\n",
       "      <td>macmanes</td>\n",
       "      <td>720</td>\n",
       "      <td>1209600.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-10T23:29:38</td>\n",
       "      <td>xl</td>\n",
       "      <td>macmanes</td>\n",
       "      <td>720</td>\n",
       "      <td>1209600.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-10T23:30:38</td>\n",
       "      <td>l</td>\n",
       "      <td>macmanes</td>\n",
       "      <td>720</td>\n",
       "      <td>1209600.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time nodeType      user  mem    reqTime  jobid\n",
       "0  2018-07-10T23:28:38        l  macmanes  720  1209600.0      1\n",
       "1  2018-07-10T23:28:38       xl  macmanes  720  1209600.0      1\n",
       "2  2018-07-10T23:29:38        l  macmanes  720  1209600.0      1\n",
       "3  2018-07-10T23:29:38       xl  macmanes  720  1209600.0      1\n",
       "4  2018-07-10T23:30:38        l  macmanes  720  1209600.0      1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_backlog_graph_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For GPU/RM/LM Interactive Jobs Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_time(df_interact):\n",
    "    df_interact['Start'] = pd.to_datetime(df_interact['Start'])\n",
    "    df_interact['Submit'] = pd.to_datetime(df_interact['Submit'])\n",
    "    df_interact['Start']= df_interact['Start'].map(lambda x: dt.datetime.strftime(x, '%Y-%m-%dT%H:%M:%SZ'))\n",
    "    df_interact['Submit']= df_interact['Submit'].map(lambda x: dt.datetime.strftime(x, '%Y-%m-%dT%H:%M:%SZ'))\n",
    "    df_interact['Start']=df_interact['Start'].str[:-1]\n",
    "    df_interact['Submit']=df_interact['Submit'].str[:-1]\n",
    "    df_interact[\"Start\"]=df_interact[\"Start\"]+\".000\"\n",
    "    df_interact[\"Submit\"]=df_interact[\"Submit\"]+\".000\"\n",
    "    return df_interact\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Interact_graph_data(fileName,df): \n",
    "    df_backlog=df.dropna(subset=[\"Start\",\"End\",\"Submit\"])\n",
    "    if \"gpu\" in fileName:\n",
    "        df_backlog=df.dropna(subset=[\"Alloc_gres/gpu\"])\n",
    "        \n",
    "    df_backlog = df_backlog.drop(df_backlog[df_backlog.End=='Unknown'].index)\n",
    "    df_backlog = df_backlog.drop(df_backlog[df_backlog.NodeList=='None assigned'].index)\n",
    "    df_backlog=df_backlog.reset_index(drop=True)\n",
    "    \n",
    "    if \"gpu\" in fileName:\n",
    "        df_interact=df_backlog[df_backlog['JobName']==\"Interact\"].loc[:,[\"Start\",\"Submit\",\"Partition\",\"Alloc_gres/gpu\",\"Alloc_NODE\"]]\n",
    "    elif \"rm\" in fileName:\n",
    "        df_interact=df_backlog[df_backlog['JobName']==\"Interact\"].loc[:,[\"Start\",\"Submit\",\"Partition\",\"Alloc_NODE\"]]\n",
    "    else:\n",
    "        df_interact=df_backlog[df_backlog['JobName']==\"Interact\"].loc[:,[\"Start\",\"Submit\",\"Partition\",\"Alloc_MEM\",\"Alloc_NODE\"]]\n",
    "\n",
    "        \n",
    "    df_interact[\"waittime\"]=[dateutil.parser.parse(df_interact.iloc[a,:][\"Start\"])-dateutil.parser.parse(df_interact.iloc[a,:][\"Submit\"]) for a in range (df_interact.shape[0])]    \n",
    "    df_interact[\"waittime\"]=df_interact[\"waittime\"].dt.total_seconds()\n",
    "    df_interact=df_interact.reset_index(drop=True)\n",
    "    \n",
    "    if \"gpu\" in fileName:\n",
    "        df_interact.columns=[\"Start\",\"Submit\",\"Partition\",\"nodeType\",\"Alloc_NODE\",\"Waittime\"]\n",
    "    elif \"rm\" in fileName:\n",
    "        df_interact.columns=[\"Start\",\"Submit\",\"Partition\",\"Alloc_NODE\",\"Waittime\"]\n",
    "    else:\n",
    "        df_interact.columns=[\"Start\",\"Submit\",\"nodeType\",\"Alloc_MEM\",\"Alloc_NODE\",\"Waittime\"]\n",
    "\n",
    "    df_interact=process_time(df_interact)\n",
    "    df_interact=df_interact.drop([\"Start\"],axis=1)\n",
    "    \n",
    "    if \"gpu\" in fileName:\n",
    "        df_interact.to_csv(\"interact_gpu.csv\")\n",
    "    elif \"rm\" in fileName:\n",
    "        df_interact.to_csv(\"interact_rm.csv\")        \n",
    "    else:\n",
    "        df_interact.to_csv(\"interact_lm.csv\") \n",
    "    \n",
    "    return df_interact\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 143 ms, sys: 4 µs, total: 143 ms\n",
      "Wall time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "gpu_interact_graph_data=Interact_graph_data(\"today_gpu.csv\",df_all_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Submit</th>\n",
       "      <th>Partition</th>\n",
       "      <th>nodeType</th>\n",
       "      <th>Alloc_NODE</th>\n",
       "      <th>Waittime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-19T00:14:06.000</td>\n",
       "      <td>GPU-small</td>\n",
       "      <td>p100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-19T01:18:48.000</td>\n",
       "      <td>GPU-small</td>\n",
       "      <td>p100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-19T04:07:01.000</td>\n",
       "      <td>GPU-shared</td>\n",
       "      <td>p100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-19T04:11:05.000</td>\n",
       "      <td>GPU-shared</td>\n",
       "      <td>p100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-19T04:22:39.000</td>\n",
       "      <td>GPU-shared</td>\n",
       "      <td>p100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Submit   Partition nodeType Alloc_NODE  Waittime\n",
       "0  2018-07-19T00:14:06.000   GPU-small     p100          1       0.0\n",
       "1  2018-07-19T01:18:48.000   GPU-small     p100          1       0.0\n",
       "2  2018-07-19T04:07:01.000  GPU-shared     p100          1       0.0\n",
       "3  2018-07-19T04:11:05.000  GPU-shared     p100          1       0.0\n",
       "4  2018-07-19T04:22:39.000  GPU-shared     p100          1       0.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_interact_graph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 105 ms, sys: 1e+03 µs, total: 106 ms\n",
      "Wall time: 107 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "rm_interact_graph_data=Interact_graph_data(\"today_rm.csv\",df_all_rm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Submit</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Alloc_NODE</th>\n",
       "      <th>Waittime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-18T17:34:47.000</td>\n",
       "      <td>RM</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-18T19:40:23.000</td>\n",
       "      <td>RM</td>\n",
       "      <td>4</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-18T19:52:25.000</td>\n",
       "      <td>RM</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-18T20:36:09.000</td>\n",
       "      <td>RM</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-18T23:39:07.000</td>\n",
       "      <td>RM</td>\n",
       "      <td>4</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Submit Partition Alloc_NODE  Waittime\n",
       "0  2018-07-18T17:34:47.000        RM          4       0.0\n",
       "1  2018-07-18T19:40:23.000        RM          4      60.0\n",
       "2  2018-07-18T19:52:25.000        RM          3       0.0\n",
       "3  2018-07-18T20:36:09.000        RM          4       0.0\n",
       "4  2018-07-18T23:39:07.000        RM          4     194.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_interact_graph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.7 ms, sys: 1 ms, total: 28.7 ms\n",
      "Wall time: 29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "lm_interact_graph_data=Interact_graph_data(\"today_lm.csv\",df_all_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Submit</th>\n",
       "      <th>nodeType</th>\n",
       "      <th>Alloc_MEM</th>\n",
       "      <th>Alloc_NODE</th>\n",
       "      <th>Waittime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-18T20:04:35.000</td>\n",
       "      <td>l</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-18T23:18:50.000</td>\n",
       "      <td>l</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-19T09:10:35.000</td>\n",
       "      <td>l</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-19T09:11:19.000</td>\n",
       "      <td>l</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-19T11:09:11.000</td>\n",
       "      <td>l</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Submit nodeType Alloc_MEM Alloc_NODE  Waittime\n",
       "0  2018-07-18T20:04:35.000        l       200          1       0.0\n",
       "1  2018-07-18T23:18:50.000        l       200          1       0.0\n",
       "2  2018-07-19T09:10:35.000        l       200          1       0.0\n",
       "3  2018-07-19T09:11:19.000        l       200          1       0.0\n",
       "4  2018-07-19T11:09:11.000        l       128          1      41.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_interact_graph_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
